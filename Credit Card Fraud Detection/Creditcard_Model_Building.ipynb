{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4AIqxCnHntc1"
   },
   "source": [
    "## Model Building with imbalanced data\n",
    "We are going to build models on below mentioned algorithms and we will compare for the best model. We are not building models on SVM,  and KNN as these algorithms are computationaly expensive and need more computational resources specially for the SVM and KNN.  Skipped models' process is computationally very expensive when we have very large data set. We do not have these resource available so we are skipping these models. Working with below models:\n",
    "    - Logistic Regression\n",
    "    - Decision Tree\n",
    "    - RandomForest\n",
    "    - XGBoost\n",
    "\n",
    "#### Metric selection on imbalance data\n",
    "We are going to use ROC-AUC score as the evaluation metric for the model evaluation purpose. As the data is highly imbalanced and we have only 0.17% fraud cases in the whole data, accuracy will not be the right metric to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4qhHpqgIntc1",
    "outputId": "0a0a6e3f-804d-4385-b6fa-39a8ba0e8f1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   0.998271\n",
       "1   0.001729\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class imbalance\n",
    "y_train.value_counts()/y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwdjErmEntc1"
   },
   "source": [
    "#  Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "avoQbN60ntc1",
    "outputId": "0176de8a-0005-48a4-f6d7-315a91355301"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception calling callback for <Future at 0x1fa194d1040 state=finished raised BrokenProcessPool>\n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 407, in _process_worker\n",
      "    call_item = call_queue.get(block=True, timeout=timeout)\n",
      "  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\multiprocessing\\queues.py\", line 116, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\sklearn\\__init__.py\", line 82, in <module>\n",
      "    from .base import clone\n",
      "  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\sklearn\\base.py\", line 17, in <module>\n",
      "    from .utils import _IS_32BIT\n",
      "  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 28, in <module>\n",
      "    from .fixes import np_version, parse_version\n",
      "  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 20, in <module>\n",
      "    import scipy.stats\n",
      "  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\scipy\\stats\\__init__.py\", line 453, in <module>\n",
      "    from ._stats_py import *\n",
      "  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\scipy\\stats\\_stats_py.py\", line 44, in <module>\n",
      "    from . import distributions\n",
      "  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\scipy\\stats\\distributions.py\", line 8, in <module>\n",
      "    from ._distn_infrastructure import (rv_discrete, rv_continuous, rv_frozen)\n",
      "  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py\", line 24, in <module>\n",
      "    from scipy import optimize\n",
      "  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\scipy\\optimize\\__init__.py\", line 399, in <module>\n",
      "    from ._optimize import *\n",
      "  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 33, in <module>\n",
      "    from scipy.sparse.linalg import LinearOperator\n",
      "  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\scipy\\sparse\\linalg\\__init__.py\", line 130, in <module>\n",
      "    from . import isolve, dsolve, interface, eigen, matfuncs\n",
      "  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\scipy\\sparse\\linalg\\eigen\\__init__.py\", line 11, in <module>\n",
      "    from .arpack import *\n",
      "  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\scipy\\sparse\\linalg\\eigen\\arpack\\__init__.py\", line 22, in <module>\n",
      "    from .arpack import *\n",
      "  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\scipy\\sparse\\linalg\\eigen\\arpack\\arpack.py\", line 53, in <module>\n",
      "    from scipy.sparse.linalg.eigen.lobpcg import lobpcg\n",
      "  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\scipy\\sparse\\linalg\\eigen\\lobpcg\\__init__.py\", line 12, in <module>\n",
      "    from .lobpcg import *\n",
      "  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\scipy\\sparse\\linalg\\eigen\\lobpcg\\lobpcg.py\", line 25, in <module>\n",
      "    from scipy.sparse.sputils import bmat\n",
      "ImportError: cannot import name 'bmat' from 'scipy.sparse.sputils' (C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\scipy\\sparse\\sputils.py)\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\joblib\\externals\\loky\\_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\joblib\\parallel.py\", line 359, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\joblib\\parallel.py\", line 794, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 531, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\joblib\\externals\\loky\\reusable_executor.py\", line 177, in submit\n",
      "    return super(_ReusablePoolExecutor, self).submit(\n",
      "  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 1115, in submit\n",
      "    raise self._flags.broken\n",
      "joblib.externals.loky.process_executor.BrokenProcessPool: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 407, in _process_worker\n    call_item = call_queue.get(block=True, timeout=timeout)\n  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\multiprocessing\\queues.py\", line 116, in get\n    return _ForkingPickler.loads(res)\n  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\sklearn\\__init__.py\", line 82, in <module>\n    from .base import clone\n  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\sklearn\\base.py\", line 17, in <module>\n    from .utils import _IS_32BIT\n  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 28, in <module>\n    from .fixes import np_version, parse_version\n  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 20, in <module>\n    import scipy.stats\n  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\scipy\\stats\\__init__.py\", line 453, in <module>\n    from ._stats_py import *\n  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\scipy\\stats\\_stats_py.py\", line 44, in <module>\n    from . import distributions\n  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\scipy\\stats\\distributions.py\", line 8, in <module>\n    from ._distn_infrastructure import (rv_discrete, rv_continuous, rv_frozen)\n  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py\", line 24, in <module>\n    from scipy import optimize\n  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\scipy\\optimize\\__init__.py\", line 399, in <module>\n    from ._optimize import *\n  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\scipy\\optimize\\_optimize.py\", line 33, in <module>\n    from scipy.sparse.linalg import LinearOperator\n  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\scipy\\sparse\\linalg\\__init__.py\", line 130, in <module>\n    from . import isolve, dsolve, interface, eigen, matfuncs\n  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\scipy\\sparse\\linalg\\eigen\\__init__.py\", line 11, in <module>\n    from .arpack import *\n  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\scipy\\sparse\\linalg\\eigen\\arpack\\__init__.py\", line 22, in <module>\n    from .arpack import *\n  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\scipy\\sparse\\linalg\\eigen\\arpack\\arpack.py\", line 53, in <module>\n    from scipy.sparse.linalg.eigen.lobpcg import lobpcg\n  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\scipy\\sparse\\linalg\\eigen\\lobpcg\\__init__.py\", line 12, in <module>\n    from .lobpcg import *\n  File \"C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\scipy\\sparse\\linalg\\eigen\\lobpcg\\lobpcg.py\", line 25, in <module>\n    from scipy.sparse.sputils import bmat\nImportError: cannot import name 'bmat' from 'scipy.sparse.sputils' (C:\\Users\\monik\\.conda\\envs\\monika_env\\lib\\site-packages\\scipy\\sparse\\sputils.py)\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [124]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m model_cv \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator \u001b[38;5;241m=\u001b[39m LogisticRegression(),\n\u001b[0;32m      8\u001b[0m                         param_grid \u001b[38;5;241m=\u001b[39m params, \n\u001b[0;32m      9\u001b[0m                         scoring\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m                         verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     13\u001b[0m                         return_train_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#perform hyperparameter tuning\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43mmodel_cv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#print the evaluation result by choosing a evaluation metric\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest ROC AUC score: \u001b[39m\u001b[38;5;124m'\u001b[39m, model_cv\u001b[38;5;241m.\u001b[39mbest_score_)\n",
      "File \u001b[1;32m~\\.conda\\envs\\monika_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    885\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 891\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    895\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\.conda\\envs\\monika_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1391\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1392\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\monika_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    835\u001b[0m         )\n\u001b[0;32m    836\u001b[0m     )\n\u001b[1;32m--> 838\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    857\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    860\u001b[0m     )\n",
      "File \u001b[1;32m~\\.conda\\envs\\monika_env\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\.conda\\envs\\monika_env\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\.conda\\envs\\monika_env\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\monika_env\\lib\\concurrent\\futures\\_base.py:444\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 444\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32m~\\.conda\\envs\\monika_env\\lib\\concurrent\\futures\\_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    391\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    392\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\monika_env\\lib\\site-packages\\joblib\\externals\\loky\\_base.py:625\u001b[0m, in \u001b[0;36mFuture._invoke_callbacks\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_done_callbacks:\n\u001b[0;32m    624\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 625\u001b[0m         \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[0;32m    627\u001b[0m         LOGGER\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexception calling callback for \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\monika_env\\lib\\site-packages\\joblib\\parallel.py:359\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.__call__\u001b[1;34m(self, out)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 359\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\monika_env\\lib\\site-packages\\joblib\\parallel.py:794\u001b[0m, in \u001b[0;36mParallel.dispatch_next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdispatch_next\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;124;03m\"\"\"Dispatch more data for parallel processing\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \n\u001b[0;32m    789\u001b[0m \u001b[38;5;124;03m    This method is meant to be called concurrently by the multiprocessing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    792\u001b[0m \n\u001b[0;32m    793\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 794\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_original_iterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    795\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    796\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\monika_env\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\monika_env\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\.conda\\envs\\monika_env\\lib\\site-packages\\joblib\\_parallel_backends.py:531\u001b[0m, in \u001b[0;36mLokyBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 531\u001b[0m     future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_workers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSafeFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    532\u001b[0m     future\u001b[38;5;241m.\u001b[39mget \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_future_result, future)\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\monika_env\\lib\\site-packages\\joblib\\externals\\loky\\reusable_executor.py:177\u001b[0m, in \u001b[0;36m_ReusablePoolExecutor.submit\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msubmit\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_submit_resize_lock:\n\u001b[1;32m--> 177\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_ReusablePoolExecutor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\monika_env\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:1115\u001b[0m, in \u001b[0;36mProcessPoolExecutor.submit\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1113\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flags\u001b[38;5;241m.\u001b[39mshutdown_lock:\n\u001b[0;32m   1114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flags\u001b[38;5;241m.\u001b[39mbroken \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1115\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flags\u001b[38;5;241m.\u001b[39mbroken\n\u001b[0;32m   1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flags\u001b[38;5;241m.\u001b[39mshutdown:\n\u001b[0;32m   1117\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ShutdownExecutorError(\n\u001b[0;32m   1118\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcannot schedule new futures after shutdown\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable."
     ]
    }
   ],
   "source": [
    "# Logistic Regression parameters for K-fold cross vaidation\n",
    "params = {\"C\": [0.01, 0.1, 1, 10, 100, 1000]}\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "#perform cross validation\n",
    "model_cv = GridSearchCV(estimator = LogisticRegression(),\n",
    "                        param_grid = params, \n",
    "                        scoring= 'roc_auc', \n",
    "                        cv = folds, \n",
    "                        n_jobs=-1,\n",
    "                        verbose = 1,\n",
    "                        return_train_score=True) \n",
    "#perform hyperparameter tuning\n",
    "model_cv.fit(X_train, y_train)\n",
    "#print the evaluation result by choosing a evaluation metric\n",
    "print('Best ROC AUC score: ', model_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wjoRd798ntc2",
    "outputId": "328e7fb3-7a19-4eb6-b63a-4d405da0639b"
   },
   "outputs": [],
   "source": [
    "#print the optimum value of hyperparameters\n",
    "print('Best hyperparameters: ', model_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "id": "FHhZ7sJUntc2",
    "outputId": "e855540a-160c-4f37-cb48-5aade4f0aa23"
   },
   "outputs": [],
   "source": [
    "# cross validation results\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "jrZlr4L_ntc2",
    "outputId": "bea68ea6-6cff-4d08-f2a5-86447fedf411"
   },
   "outputs": [],
   "source": [
    "# plot of C versus train and validation scores\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(cv_results['param_C'], cv_results['mean_test_score'])\n",
    "plt.plot(cv_results['param_C'], cv_results['mean_train_score'])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.legend(['test result', 'train result'], loc='upper left')\n",
    "plt.xscale('log')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PuGs1yGntc2"
   },
   "source": [
    "#### Logistic Regression with optimal C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YNvkZfaXntc2",
    "outputId": "87094d77-4ce4-4b8b-c525-e623425681bd"
   },
   "outputs": [],
   "source": [
    " model_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QSrfuu2-ntc2",
    "outputId": "95d8d85e-6649-4376-f588-2e203ba583bb"
   },
   "outputs": [],
   "source": [
    "# Instantiating the model with best C\n",
    "log_reg_imb_model = model_cv.best_estimator_\n",
    "\n",
    "# Fitting the model on train dataset\n",
    "log_reg_imb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dHTtNeLWntc2"
   },
   "source": [
    "#### Prediction and model evalution on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8K4D0VNkntc2"
   },
   "outputs": [],
   "source": [
    "# Creating function to display ROC-AUC score, f1 score and classification report\n",
    "def display_scores(y_test, y_pred):\n",
    "    '''\n",
    "    Display ROC-AUC score, f1 score and classification report of a model.\n",
    "    '''\n",
    "    print(f\"F1 Score: {round(f1_score(y_test, y_pred)*100,2)}%\") \n",
    "    print(\"\\n\\n\")\n",
    "    print(f\"Classification Report: \\n {classification_report(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oKGkGL3Intc2"
   },
   "outputs": [],
   "source": [
    "# Predictions on the train set\n",
    "y_train_pred = log_reg_imb_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42ZAFmfqntc2",
    "outputId": "e35d1500-57a2-4a8c-f7c1-98ba5c1f15c1"
   },
   "outputs": [],
   "source": [
    "display_scores(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-bJH4GAMntc2"
   },
   "outputs": [],
   "source": [
    "# ROC Curve function\n",
    "def draw_roc( actual, probs ):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n",
    "                                              drop_intermediate = False )\n",
    "    auc_score = metrics.roc_auc_score( actual, probs )\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7e7Ko7dentc3"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_train_pred_proba = log_reg_imb_model.predict_proba(X_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "jxTOQLWGntc3",
    "outputId": "63d5edde-079f-4605-c608-4ee15eaf316c"
   },
   "outputs": [],
   "source": [
    "# Plot the ROC curve\n",
    "draw_roc(y_train, y_train_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxcApm59ntc3"
   },
   "source": [
    "#### Evaluating the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8BXWLeOxntc3",
    "outputId": "8eaa0949-2f8d-48c0-fc3a-c8f6797b63ff"
   },
   "outputs": [],
   "source": [
    "# Making prediction on the test set\n",
    "y_test_pred = log_reg_imb_model.predict(X_test)\n",
    "display_scores(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RkK9JrFfntc3"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_test_pred_proba = log_reg_imb_model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "mTGip26wntc3",
    "outputId": "b3faf868-027b-42c0-f17f-07745b14a82f"
   },
   "outputs": [],
   "source": [
    "# Plot the ROC curve\n",
    "draw_roc(y_test, y_test_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ld40AXHHntc3"
   },
   "source": [
    "We can see very good ROC on the test data set 0.97."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-60v9ta7ntc3"
   },
   "source": [
    "#### Model Summary\n",
    "\n",
    "- Train set\n",
    "    -     ROC : 98%\n",
    "    - F1 Score: 74.47%\n",
    "    \n",
    "    \n",
    "- Test set\n",
    "    -     ROC : 97%\n",
    "    - F1 score: 72.83%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-GmQyDY1ntc3"
   },
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afu6eEnbntc3",
    "outputId": "383db171-4191-433c-c1f7-7fb8ccaa2bd3"
   },
   "outputs": [],
   "source": [
    "# Create the parameter grid \n",
    "param_grid = {\n",
    "    'max_depth': range(5, 15, 5),\n",
    "    'min_samples_leaf': range(50, 150, 50),\n",
    "    'min_samples_split': range(50, 150, 50),\n",
    "}\n",
    "\n",
    "\n",
    "# Instantiate the grid search model\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator = dtree, \n",
    "                           param_grid = param_grid, \n",
    "                           scoring= 'roc_auc',\n",
    "                           cv = 5, \n",
    "                           n_jobs=-1,\n",
    "                           verbose = 1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "qqdPwj-Sntc3",
    "outputId": "1caaa485-3cb9-4c41-e43e-046610f34fac"
   },
   "outputs": [],
   "source": [
    "# cv results\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vckjiKekntc3",
    "outputId": "1b2b860f-e5f3-4dfa-917a-cc0fb5552865"
   },
   "outputs": [],
   "source": [
    "# Printing the optimal score and hyperparameters\n",
    "print(\"Best roc auc score : \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Exm8YHErntc3",
    "outputId": "25858ba2-81b8-480e-ec77-993900612de4"
   },
   "outputs": [],
   "source": [
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9DITjacntc3"
   },
   "source": [
    "#### Decision Tree with optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "prR4a4msntc4",
    "outputId": "d833e875-d843-4a48-c733-f1a00a88d77c"
   },
   "outputs": [],
   "source": [
    "# Model with optimal hyperparameters\n",
    "dt_imb_model = grid_search.best_estimator_\n",
    "\n",
    "dt_imb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HG0rSb0Fntc4"
   },
   "source": [
    "#### Prediction on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8hvQXHTtntc4",
    "outputId": "26a41d06-18be-406c-b4f8-d02d045e124e"
   },
   "outputs": [],
   "source": [
    "y_train_pred = dt_imb_model.predict(X_train)\n",
    "display_scores(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "p-DFhcnQntc4",
    "outputId": "832547eb-7dbe-4f1b-d2ae-ffad950059d8"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_train_pred_proba = dt_imb_model.predict_proba(X_train)[:,1]\n",
    "\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_train, y_train_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E25hUNLmntc4"
   },
   "source": [
    "#### Evaluating the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a-C1p0fyntc4",
    "outputId": "12377776-be07-4d01-ad93-503905ef8c15"
   },
   "outputs": [],
   "source": [
    "y_test_pred = dt_imb_model.predict(X_test)\n",
    "display_scores(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "i3_JuUHtntc4",
    "outputId": "31828b67-656e-4382-b99d-3ffdd700d122"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_test_pred_proba = dt_imb_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_test, y_test_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTVBYXXlntc4"
   },
   "source": [
    "#### Model Summary\n",
    "\n",
    "- Train set\n",
    "    - ROC Score: 94%\n",
    "    - F1 score : 68.32%\n",
    "    \n",
    "    \n",
    "- Test set\n",
    "    - ROC Score: 94%\n",
    "    - F1 score : 61.73%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-J9uIcgntc4"
   },
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZulwxgS9ntc4",
    "outputId": "1dc1a5f4-e4cd-4ec0-e508-faacf97833f2"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Create the parameter grid \n",
    "param_grid = {\n",
    "    'max_depth': range(5, 15, 5),\n",
    "    'min_samples_leaf': range(50, 150, 50),\n",
    "    'min_samples_split': range(50, 150, 50),\n",
    "}\n",
    "\n",
    "\n",
    "# Instantiate the grid search model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator = rf, \n",
    "                           param_grid = param_grid, \n",
    "                           scoring= 'roc_auc',\n",
    "                           cv = 5, \n",
    "                           n_jobs=-1,\n",
    "                           verbose = 1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "3Gbsl0Q1ntc4",
    "outputId": "986b7c39-3366-4e16-9714-ed2decabe9c9"
   },
   "outputs": [],
   "source": [
    "# cv results\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3gRTKqUBntc4",
    "outputId": "9ed31ecd-2734-4d6b-ce2b-5907ab9c26c5"
   },
   "outputs": [],
   "source": [
    "# Printing the optimal score and hyperparameters\n",
    "print(\"Best roc auc score : \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dOu67K2Vntc4",
    "outputId": "a285c09f-93f5-47de-864f-f4f394b0d136"
   },
   "outputs": [],
   "source": [
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3V8JldCentc4"
   },
   "source": [
    "#### Random forest with optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-bbo078ntc5",
    "outputId": "bbb72c9d-52d1-48bf-85cc-2301ce1e7064"
   },
   "outputs": [],
   "source": [
    "# Model with optimal hyperparameters\n",
    "rf_imb_model = grid_search.best_estimator_\n",
    "\n",
    "rf_imb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5t4YxPrntc5"
   },
   "source": [
    "#### Prediction on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yyEhTcM7ntc5",
    "outputId": "d4a5bba0-7d3a-4d78-e02b-f05bd6848cc9"
   },
   "outputs": [],
   "source": [
    "y_train_pred = rf_imb_model.predict(X_train)\n",
    "display_scores(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "mmfYbx7hntc5",
    "outputId": "ca2814e3-ffc9-4728-a012-bc275fe299bf"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_train_pred_proba = rf_imb_model.predict_proba(X_train)[:,1]\n",
    "\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_train, y_train_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQu2cctrntc5"
   },
   "source": [
    "#### Evaluating the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PJdqWv-9ntc5",
    "outputId": "b7eafad8-9bb1-4a00-cba8-43c75c0d0619"
   },
   "outputs": [],
   "source": [
    "y_test_pred = rf_imb_model.predict(X_test)\n",
    "display_scores(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "BiRZOXROntc5",
    "outputId": "b9e187b0-31d5-44aa-f4b1-8ed45ab7c052"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_test_pred_proba = rf_imb_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_test, y_test_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xaVxTzEntc5"
   },
   "source": [
    "#### Model Summary\n",
    "\n",
    "- Train set\n",
    "    - ROC Score: 100%\n",
    "    - F1 score : 75.32%\n",
    "    \n",
    "    \n",
    "- Test set\n",
    "    - ROC Score: 98%\n",
    "    - F1 score : 75.56%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqPKq77Cntc5"
   },
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LpD6BfxJntc5",
    "outputId": "71b0a96c-b14c-4a71-f80f-36eadd699641"
   },
   "outputs": [],
   "source": [
    "# creating a KFold object \n",
    "folds = 5\n",
    "\n",
    "# specify range of hyperparameters\n",
    "param_grid = {'learning_rate': [0.2, 0.6], \n",
    "             'subsample': [0.3, 0.6, 0.9]}          \n",
    "\n",
    "\n",
    "# specify model\n",
    "xgb_model = XGBClassifier(max_depth=2, n_estimators=200)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = xgb_model, \n",
    "                        param_grid = param_grid, \n",
    "                        scoring= 'roc_auc', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        n_jobs=-1,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "Tyf8VLwDntc5",
    "outputId": "e1645206-ba40-479e-f91c-2ed6b6cf5e21"
   },
   "outputs": [],
   "source": [
    "# cv results\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5XAHDOrfntc5",
    "outputId": "bf9f1e25-6a3f-4c57-b982-56c5e169fee3"
   },
   "outputs": [],
   "source": [
    "# Printing the optimal score and hyperparameters\n",
    "print(\"Best roc auc score : \", model_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MYaFBu8zntc5",
    "outputId": "4feeb0f0-b6e8-4cd6-a9fb-038c7d83adf5"
   },
   "outputs": [],
   "source": [
    "print(model_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "699lunQUntc5",
    "outputId": "26bf319f-9d1b-4ab0-b7b1-77f11b9c1762"
   },
   "outputs": [],
   "source": [
    "# Printing best params\n",
    "model_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMWWyOYwntc5"
   },
   "source": [
    "#### XGBoost model with optimal hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-c3cdke5ntc6",
    "outputId": "ae9ef638-f77b-4bfb-ebcb-d4a859c20899",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit model on training data\n",
    "xgb_imb_model = model_cv.best_estimator_\n",
    "xgb_imb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zwumL0Dntc6"
   },
   "source": [
    "#### Model evaluation on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6cjSPx5vntc6",
    "outputId": "b39fc6ec-114f-4ac2-dc2e-d432ba4b31e4"
   },
   "outputs": [],
   "source": [
    "# Predictions on the train set\n",
    "y_train_pred = xgb_imb_model.predict(X_train)\n",
    "\n",
    "display_scores(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "b9ef34QDntc6",
    "outputId": "49f7d449-3809-4a79-b7d2-6f9a61010494"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_train_pred_proba_imb_xgb = xgb_imb_model.predict_proba(X_train)[:,1]\n",
    "\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_train, y_train_pred_proba_imb_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-wixidlntc6"
   },
   "source": [
    "#### Evaluating the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AdBzraDFntc6",
    "outputId": "6799e874-97d0-4a99-c7c7-2e91f24a2adb"
   },
   "outputs": [],
   "source": [
    "# Predictions on the test set\n",
    "y_test_pred = xgb_imb_model.predict(X_test)\n",
    "display_scores(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "Nksxun1Antc6",
    "outputId": "6fda419f-5020-4c2c-9b3d-bcbde65ac25c"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_test_pred_proba = xgb_imb_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_test, y_test_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QsyQthz7ntc6"
   },
   "source": [
    "#### Model Summary\n",
    "\n",
    "- Train set\n",
    "    - ROC score: 100%\n",
    "    - F1 score: 99.75%\n",
    "- Test set\n",
    "    - ROC score: 98%\n",
    "    - F1 score: 82.87%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VrIEmkEXntc6"
   },
   "source": [
    "**XGBoost model is giving good performance on the unbalanced data among these 4 models. ROC-AUC score on the train data is 100% and on test data 98%.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hcbgfNXDntc6"
   },
   "source": [
    "### Print the important features of the best model to understand the dataset\n",
    "- This will not give much explanation on the already transformed dataset\n",
    "- But it will help us in understanding if the dataset is not PCA transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m5Y6SnRRntc6",
    "outputId": "f795cb96-cbb1-4c49-a747-f668896cb2eb"
   },
   "outputs": [],
   "source": [
    "var_imp = []\n",
    "for i in xgb_imb_model.feature_importances_:\n",
    "    var_imp.append(i)\n",
    "print('Top var =', var_imp.index(np.sort(xgb_imb_model.feature_importances_)[-1])+1)\n",
    "print('2nd Top var =', var_imp.index(np.sort(xgb_imb_model.feature_importances_)[-2])+1)\n",
    "print('3rd Top var =', var_imp.index(np.sort(xgb_imb_model.feature_importances_)[-3])+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "gHxGQ6XLntc6",
    "outputId": "6b913c81-49ea-4777-a8a4-f5849b7d01a8"
   },
   "outputs": [],
   "source": [
    "# Variable on Index-17 and Index-14 seems to be the top 2 variables\n",
    "top_var_index = var_imp.index(np.sort(xgb_imb_model.feature_importances_)[-1])\n",
    "second_top_var_index = var_imp.index(np.sort(xgb_imb_model.feature_importances_)[-2])\n",
    "\n",
    "X_train_1 = X_train.to_numpy()[np.where(y_train==1.0)]\n",
    "X_train_0 = X_train.to_numpy()[np.where(y_train==0.0)]\n",
    "\n",
    "np.random.shuffle(X_train_0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "plt.scatter(X_train_1[:, top_var_index], X_train_1[:, second_top_var_index], label='Actual Class-1 Examples')\n",
    "plt.scatter(X_train_0[:X_train_1.shape[0], top_var_index], X_train_0[:X_train_1.shape[0], second_top_var_index],\n",
    "            label='Actual Class-0 Examples')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmDPWWByntc6"
   },
   "source": [
    "#### Print the FPR,TPR & select the best threshold from the roc curve for the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HohCMhCrntc7",
    "outputId": "c6fd42cd-743c-42c3-818f-a1b73366ebd8"
   },
   "outputs": [],
   "source": [
    "print('Train auc =', metrics.roc_auc_score(y_train, y_train_pred_proba_imb_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l8G7Ve5Hntc7",
    "outputId": "4d110d9e-bbf4-4a38-8c7e-8be907a5e530"
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_train, y_train_pred_proba_imb_xgb)\n",
    "threshold = thresholds[np.argmax(tpr-fpr)]\n",
    "print(\"Threshold=\",threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aBsTwgE-ntc7"
   },
   "source": [
    "We can see that the threshold is 0.46, for which the TPR is the highest and FPR is the lowest and we got the best ROC score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZDmIa-Hntc7"
   },
   "source": [
    "## Model building with balancing Classes\n",
    "\n",
    "We are going to perform below over sampling approaches for handling data imbalance and we will pick the best approach based on model performance.\n",
    "- Random Oversampling\n",
    "- SMOTE\n",
    "- ADASYN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "no4EGn1Ontc7"
   },
   "source": [
    "### Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fjFON6hDntc7",
    "outputId": "5d14054d-1c19-4270-d3e5-5d792b0b7b92"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# define oversampling strategy\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "#fit and apply the transform\n",
    "X_over, y_over = oversample.fit_resample(X_train, y_train)\n",
    "X_over.shape, y_over.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hXyGesjgntc7",
    "outputId": "f547b2ce-3e48-4f0c-ba27-ccbc65c0a2a7"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# Befor sampling class distribution\n",
    "print('Before sampling class distribution:-',Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sgeyA5BXntc7",
    "outputId": "3f124454-c8df-4224-fa41-49a03a817de2"
   },
   "outputs": [],
   "source": [
    "# new class distribution \n",
    "print('New class distribution:-',Counter(y_over))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQwRr_eEntc7"
   },
   "source": [
    "# Logistic Regrassion with Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HZsjIbIJntc7",
    "outputId": "9e4d3b03-cf74-4277-cd92-bb83d7c4fbb0"
   },
   "outputs": [],
   "source": [
    "# Logistic Regression parameters for K-fold cross vaidation\n",
    "params = {\"C\": [0.01, 0.1, 1, 10, 100, 1000]}\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "#perform cross validation\n",
    "model_cv = GridSearchCV(estimator = LogisticRegression(),\n",
    "                        param_grid = params, \n",
    "                        scoring= 'roc_auc', \n",
    "                        cv = folds, \n",
    "                        n_jobs=-1,\n",
    "                        verbose = 1,\n",
    "                        return_train_score=True) \n",
    "#perform hyperparameter tuning\n",
    "model_cv.fit(X_over, y_over)\n",
    "#print the evaluation result by choosing a evaluation metric\n",
    "print('Best ROC AUC score: ', model_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jhv0u0qkntc7",
    "outputId": "f82571b1-c30f-4a35-dd3d-ec15103acbed"
   },
   "outputs": [],
   "source": [
    "#print the optimum value of hyperparameters\n",
    "print('Best hyperparameters: ', model_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "id": "bXWStXKGntc7",
    "outputId": "cce52c7c-7fc2-4148-9d53-3aaafc5512a4"
   },
   "outputs": [],
   "source": [
    "# cross validation results\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "6z4R0HODntc7",
    "outputId": "41128519-9aee-4a8e-929d-ca6ccfd2d8cf"
   },
   "outputs": [],
   "source": [
    "# plot of C versus train and validation scores\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(cv_results['param_C'], cv_results['mean_test_score'])\n",
    "plt.plot(cv_results['param_C'], cv_results['mean_train_score'])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.legend(['test result', 'train result'], loc='upper left')\n",
    "plt.xscale('log')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pc2ylpF6ntc7"
   },
   "source": [
    "#### Logistic Regression with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2sMcFFj5ntc7",
    "outputId": "f1204840-e934-491a-be11-30a8d2aa9436"
   },
   "outputs": [],
   "source": [
    "model_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SLO33CQXntc8"
   },
   "outputs": [],
   "source": [
    "# Instantiating the model\n",
    "logreg_over = LogisticRegression(C=1000)\n",
    "\n",
    "# Fitting the model with train data\n",
    "logreg_over_model = logreg_over.fit(X_over, y_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8IiglDd8ntc8"
   },
   "source": [
    "#### Evaluating the model on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9BRfVmngntc8"
   },
   "outputs": [],
   "source": [
    "# Predictions on the train set\n",
    "y_train_pred = logreg_over_model.predict(X_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6TsalosYntc8",
    "outputId": "3cbef6a3-3174-46df-a7f5-35e269073456"
   },
   "outputs": [],
   "source": [
    "# Printing scores\n",
    "display_scores(y_over, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "VUIlAQmvntc8",
    "outputId": "5cbdf35a-2432-4b37-cb6a-6c301c55ea3a"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_train_pred_proba = logreg_over_model.predict_proba(X_over)[:,1]\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_over, y_train_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkmcRwysntc8"
   },
   "source": [
    "#### Evaluating on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbnv3WDYntc8",
    "outputId": "70c3b97e-ab70-42ba-eb46-486498468ca2"
   },
   "outputs": [],
   "source": [
    "# Evaluating on test data\n",
    "y_test_pred = logreg_over_model.predict(X_test)\n",
    "\n",
    "# Printing the scores\n",
    "display_scores(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "68xf86-rntc8",
    "outputId": "1bb0d74c-e887-4adf-e898-46b68a16561e"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_test_pred_proba = logreg_over_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_test, y_test_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9U_HgMentc8"
   },
   "source": [
    "#### Model Summary\n",
    "- Train set\n",
    "    - ROC score : 99%\n",
    "    - F1 score: 94.97%\n",
    "- Test set\n",
    "    - ROC score : 97%\n",
    "    - F1 score: 10.11%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmxveV1fntc8"
   },
   "source": [
    "# Decision Tree with Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iFE9aVauntc8",
    "outputId": "de33993f-4d32-4aeb-9efc-1ea5230e40a2"
   },
   "outputs": [],
   "source": [
    "# Create the parameter grid \n",
    "param_grid = {\n",
    "    'max_depth': range(5, 15, 5),\n",
    "    'min_samples_leaf': range(50, 150, 50),\n",
    "    'min_samples_split': range(50, 150, 50),\n",
    "}\n",
    "\n",
    "\n",
    "# Instantiate the grid search model\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator = dtree, \n",
    "                           param_grid = param_grid, \n",
    "                           scoring= 'roc_auc',\n",
    "                           cv = 5, \n",
    "                           n_jobs=-1,\n",
    "                           verbose = 1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_over,y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o_PUsFkuntc8",
    "outputId": "104a4da6-fb8e-4fc3-9fd4-8f69f5c4cfa1"
   },
   "outputs": [],
   "source": [
    "# Printing the optimal roc score and hyperparameters\n",
    "print(\"Best roc auc score : \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mowUSRrantc8",
    "outputId": "04322a03-5e6c-4b8b-b665-c782ef4ad9ac"
   },
   "outputs": [],
   "source": [
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ls8y32zqntc8"
   },
   "source": [
    "#### Decision Tree with optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "idI8mPMuntc9",
    "outputId": "46a464c3-82d3-42ca-e72b-6264fc8657f4"
   },
   "outputs": [],
   "source": [
    "# Model with optimal hyperparameters\n",
    "dt_over_model = DecisionTreeClassifier(criterion = \"gini\", \n",
    "                                  random_state = 42,\n",
    "                                  max_depth=10, \n",
    "                                  min_samples_leaf=50,\n",
    "                                  min_samples_split=50)\n",
    "\n",
    "dt_over_model.fit(X_over, y_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DdL69VEjntc9"
   },
   "source": [
    "#### Model evatuation on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GmKtELCintc9",
    "outputId": "ba950ee5-824d-45c7-b840-396d3a67247f"
   },
   "outputs": [],
   "source": [
    "# Predictions on the train set\n",
    "y_train_pred = dt_over_model.predict(X_over)\n",
    "display_scores(y_over, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "nNYwwPBentc9",
    "outputId": "0b7b6ccd-eceb-4ddc-d93f-348a01b4974f"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_train_pred_proba = dt_over_model.predict_proba(X_over)[:,1]\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_over, y_train_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9VDQgKUntc9"
   },
   "source": [
    "#### Predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lhv_olwDntc9",
    "outputId": "c59e8be4-46ed-44eb-861f-f984a3ec6660"
   },
   "outputs": [],
   "source": [
    "# Evaluating model on the test data\n",
    "y_test_pred = dt_over_model.predict(X_test)\n",
    "display_scores(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "-7qT-8Yhntc9",
    "outputId": "2ca38d04-a179-4c3a-f0bd-b558630eeb4e"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_test_pred_proba = dt_over_model.predict_proba(X_test)[:,1]\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_test, y_test_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_iOwYgdHntc9"
   },
   "source": [
    "#### Model Summary\n",
    "- Train set\n",
    "    - ROC score : 100%\n",
    "    - F1 score: 99.64%\n",
    "- Test set\n",
    "    - ROC score : 92%\n",
    "    - F1 score: 25.31%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXPmSwjEntc9"
   },
   "source": [
    "# Random Forest with Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZAokUxcYntc9",
    "outputId": "ffac58c3-b414-4cab-adae-79d0b5ce5eeb"
   },
   "outputs": [],
   "source": [
    "# Create the parameter grid \n",
    "param_grid = {\n",
    "    'max_depth': range(5, 15, 5),\n",
    "    'min_samples_leaf': range(50, 150, 50),\n",
    "    'min_samples_split': range(50, 150, 50),\n",
    "}\n",
    "\n",
    "\n",
    "# Instantiate the grid search model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator = rf, \n",
    "                           param_grid = param_grid, \n",
    "                           scoring= 'roc_auc',\n",
    "                           cv = 5, \n",
    "                           n_jobs=-1,\n",
    "                           verbose = 1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_over,y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kjwkqt7zntc9"
   },
   "outputs": [],
   "source": [
    "# Printing the optimal roc score and hyperparameters\n",
    "print(\"Best roc auc score : \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOAbpKZ1ntc9"
   },
   "source": [
    "#### Random Forest with optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PKIFSzMbntc-"
   },
   "outputs": [],
   "source": [
    "# Model with optimal hyperparameters\n",
    "rf_over_model = grid_search.best_estimator_\n",
    "\n",
    "rf_over_model.fit(X_over, y_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4bQwI3antc-"
   },
   "source": [
    "#### Model evatuation on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nSd61zbMntc-"
   },
   "outputs": [],
   "source": [
    "# Predictions on the train set\n",
    "y_train_pred = rf_over_model.predict(X_over)\n",
    "display_scores(y_over, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fI_h44aCntc-"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_train_pred_proba = rf_over_model.predict_proba(X_over)[:,1]\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_over, y_train_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJIMK8Eyntc-"
   },
   "source": [
    "#### Predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-2kiibZyntc-"
   },
   "outputs": [],
   "source": [
    "# Evaluating model on the test data\n",
    "y_test_pred = rf_over_model.predict(X_test)\n",
    "display_scores(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ERi5kDi8ntc-"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_test_pred_proba = rf_over_model.predict_proba(X_test)[:,1]\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_test, y_test_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0mkphzentc-"
   },
   "source": [
    "#### Model Summary\n",
    "- Train set\n",
    "    - ROC score : 100%\n",
    "    - F1 score: 99.72%\n",
    "- Test set\n",
    "    - ROC score : 98%\n",
    "    - F1 score: 70.49%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-D8alTMntc-"
   },
   "source": [
    "# XGBoost with Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fjSsbTj2ntc-"
   },
   "outputs": [],
   "source": [
    "# creating a KFold object \n",
    "folds = 5\n",
    "\n",
    "# specify range of hyperparameters\n",
    "param_grid = {'learning_rate': [0.2, 0.6], \n",
    "             'subsample': [0.3, 0.6, 0.9]}          \n",
    "\n",
    "\n",
    "# specify model\n",
    "xgb_model = XGBClassifier(max_depth=2, n_estimators=200)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = xgb_model, \n",
    "                        param_grid = param_grid, \n",
    "                        scoring= 'roc_auc', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        n_jobs=-1,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv.fit(X_over, y_over) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M1sRC6Syntc-"
   },
   "outputs": [],
   "source": [
    "# cv results\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bLSzsb5xntc-"
   },
   "outputs": [],
   "source": [
    "# Printing the optimal score and hyperparameters\n",
    "print(\"Best roc auc score : \", model_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dY7VfraMntc-"
   },
   "outputs": [],
   "source": [
    "print(model_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LoDQZFTWntc-"
   },
   "outputs": [],
   "source": [
    "model_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGN_YB5Nntc_"
   },
   "source": [
    "#### XGBoost with optimal hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3OMRGkwbntc_"
   },
   "outputs": [],
   "source": [
    "# fit model on training data\n",
    "xgb_over_model = model_cv.best_estimator_\n",
    "xgb_over_model.fit(X_over, y_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CklFFHjintc_"
   },
   "source": [
    "#### Model evatuation on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YKhYpFAQntc_"
   },
   "outputs": [],
   "source": [
    "# Predictions on the train set\n",
    "y_train_pred = xgb_over_model.predict(X_over)\n",
    "\n",
    "display_scores(y_over, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wkj2EyBnntc_"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_train_pred_proba = xgb_over_model.predict_proba(X_over)[:,1]\n",
    "\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_over, y_train_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b33c23RUntc_"
   },
   "source": [
    "#### Model evaluation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YBuuJucmntc_"
   },
   "outputs": [],
   "source": [
    "y_pred = xgb_over_model.predict(X_test)\n",
    "display_scores(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ELwFjXAqntc_"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_test_pred_proba = xgb_over_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_test, y_test_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZoAP8nzqntc_"
   },
   "source": [
    "#### Model Summary\n",
    "- Train set\n",
    "    - ROC score : 100.0%\n",
    "    - F1 score: 99.99%\n",
    "- Test set\n",
    "    - ROC score : 98%\n",
    "    - F1 score: 81.34%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yAEIol6Tntc_"
   },
   "source": [
    "## SMOTE (Synthetic Minority Oversampling Technique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGSPsfVrntc_"
   },
   "source": [
    "### Print the class distribution after applying SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gXeL6JU_ntc_"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = sm.fit_resample(X_train, y_train)\n",
    "# Artificial minority samples and corresponding minority labels from SMOTE are appended\n",
    "# below X_train and y_train respectively\n",
    "# So to exclusively get the artificial minority samples from SMOTE, we do\n",
    "X_train_smote_1 = X_train_smote[X_train.shape[0]:]\n",
    "\n",
    "X_train_1 = X_train.to_numpy()[np.where(y_train==1.0)]\n",
    "X_train_0 = X_train.to_numpy()[np.where(y_train==0.0)]\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 20]\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
    "plt.scatter(X_train_smote_1.iloc[:X_train_1.shape[0], 0], X_train_smote_1.iloc[:X_train_1.shape[0], 1],\n",
    "            label='Artificial SMOTE Class-1 Examples')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
    "plt.scatter(X_train_0[:X_train_1.shape[0], 0], X_train_0[:X_train_1.shape[0], 1], label='Actual Class-0 Examples')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvo_JZjlntc_"
   },
   "source": [
    "# Logistic Regression on balanced data with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AWCkcf8Yntc_"
   },
   "outputs": [],
   "source": [
    "# Creating KFold object with 5 splits\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=4)\n",
    "\n",
    "# Specify params\n",
    "params = {\"C\": [0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "# Specifing score as roc-auc\n",
    "model_cv = GridSearchCV(estimator = LogisticRegression(),\n",
    "                        param_grid = params, \n",
    "                        scoring= 'roc_auc', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        n_jobs=-1,\n",
    "                        return_train_score=True) \n",
    "\n",
    "# Fit the model\n",
    "model_cv.fit(X_train_smote, y_train_smote)\n",
    "#print the evaluation result by choosing a evaluation metric\n",
    "print('Best ROC AUC score: ', model_cv.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iw-l7tjQntc_"
   },
   "outputs": [],
   "source": [
    "#print the optimum value of hyperparameters\n",
    "print('Best hyperparameters: ', model_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZinUS9cantdA"
   },
   "outputs": [],
   "source": [
    "# cross validation results\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jd-KlsUhntdA"
   },
   "outputs": [],
   "source": [
    "# plot of C versus train and validation scores\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(cv_results['param_C'], cv_results['mean_test_score'])\n",
    "plt.plot(cv_results['param_C'], cv_results['mean_train_score'])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.legend(['test result', 'train result'], loc='upper left')\n",
    "plt.xscale('log')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qSeNWb1ntdA"
   },
   "source": [
    "#### Logistic Regression with optimal C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uHSswBw0ntdA"
   },
   "outputs": [],
   "source": [
    "# Printing best params\n",
    "model_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mDbHaVmTntdA"
   },
   "outputs": [],
   "source": [
    "# Instantiating the model\n",
    "logreg_smote_model = model_cv.best_estimator_\n",
    "\n",
    "# Fitting the model with balanced data\n",
    "logreg_smote_model.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Alu0KXhLntdA"
   },
   "source": [
    "#### Evaluating the model on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vah-ALSvntdA"
   },
   "outputs": [],
   "source": [
    "# Evaluating on train data\n",
    "y_train_pred = logreg_smote_model.predict(X_train_smote)\n",
    "display_scores(y_train_smote, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RyXun1_FntdA"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_train_pred_proba_smote = logreg_smote_model.predict_proba(X_train_smote)[:,1]\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_train_smote, y_train_pred_proba_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9Tw9hOBntdA"
   },
   "source": [
    "#### Evaluating on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DZyGEDTYntdA"
   },
   "outputs": [],
   "source": [
    "# Evaluating on test data\n",
    "y_test_pred = logreg_smote_model.predict(X_test)\n",
    "display_scores(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nYPo2dq0ntdA"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_test_pred_proba_smote = logreg_smote_model.predict_proba(X_test)[:,1]\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_test, y_test_pred_proba_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "boZwQObRntdA"
   },
   "source": [
    "#### Model Summary\n",
    "- Train set\n",
    "    - ROC score : 99%\n",
    "    - F1 score: 94.8%\n",
    "    \n",
    "    \n",
    "- Test set\n",
    "    - ROC score : 97%\n",
    "    - F1 score: 9.67%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tyNE13pntdB"
   },
   "source": [
    "# Decision Tree on balanced data with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fs-scXlsntdB"
   },
   "outputs": [],
   "source": [
    "# Create the parameter grid \n",
    "param_grid = {\n",
    "    'max_depth': range(5, 15, 5),\n",
    "    'min_samples_leaf': range(50, 150, 50),\n",
    "    'min_samples_split': range(50, 150, 50),\n",
    "}\n",
    "\n",
    "\n",
    "# Instantiate the grid search model\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator = dtree, \n",
    "                           param_grid = param_grid, \n",
    "                           scoring= 'roc_auc',\n",
    "                           cv = 5, \n",
    "                           n_jobs=-1,\n",
    "                           verbose = 1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LoXHJQlhntdB"
   },
   "outputs": [],
   "source": [
    "# Printing the optimal roc score and hyperparameters\n",
    "print(\"Best roc auc score : \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JE_MfPwdntdB"
   },
   "outputs": [],
   "source": [
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXgPNJ1KntdB"
   },
   "source": [
    "#### Model with optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G2EvJpoRntdB"
   },
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NopO_be6ntdB"
   },
   "outputs": [],
   "source": [
    "# Model with optimal hyperparameters\n",
    "dt_smote_model = grid_search.best_estimator_\n",
    "\n",
    "dt_smote_model.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCR8rPBpntdB"
   },
   "source": [
    "#### Evaluating the model on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GI6JwQhontdB"
   },
   "outputs": [],
   "source": [
    "# Predictions on the train set\n",
    "y_train_pred_smote = dt_smote_model.predict(X_train_smote)\n",
    "display_scores(y_train_smote, y_train_pred_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GAsDMFDvntdB"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_train_pred_proba = dt_smote_model.predict_proba(X_train_smote)[:,1]\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_train_smote, y_train_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76kF7RfLntdB"
   },
   "source": [
    "#### Evaluating the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ih_we_ZTntdB"
   },
   "outputs": [],
   "source": [
    "# Evaluating model on the test data\n",
    "y_pred = dt_smote_model.predict(X_test)\n",
    "display_scores(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l1PdYEaFntdB"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_test_pred_smote = dt_smote_model.predict_proba(X_test)[:,1]\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_test, y_test_pred_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gyXjTAnVntdB"
   },
   "source": [
    "#### Model Summary\n",
    "- Train set\n",
    "    - ROC score : 100%\n",
    "    - F1 score: 98.93%\n",
    "- Test set\n",
    "    - ROC score : 95%\n",
    "    - F1 score: 17.37%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOPGZ4huntdB"
   },
   "source": [
    "# Randomforest on balanced data with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QKgAYf4HntdB"
   },
   "outputs": [],
   "source": [
    "# Create the parameter grid \n",
    "param_grid = {\n",
    "    'max_depth': range(5, 15, 5),\n",
    "    'min_samples_leaf': range(50, 150, 50),\n",
    "    'min_samples_split': range(50, 150, 50),\n",
    "}\n",
    "\n",
    "\n",
    "# Instantiate the grid search model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = param_grid, \n",
    "                           scoring= 'roc_auc',\n",
    "                           cv = 5, \n",
    "                           n_jobs=-1,\n",
    "                           verbose = 1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dc_XkSpDntdC"
   },
   "outputs": [],
   "source": [
    "# Printing the optimal roc score and hyperparameters\n",
    "print(\"Best roc auc score : \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qyeh4_FwntdC"
   },
   "outputs": [],
   "source": [
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VVRoW0edntdC"
   },
   "source": [
    "#### Model with optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jH_NIIQ5ntdC"
   },
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZAcSH1sntdC"
   },
   "outputs": [],
   "source": [
    "# Model with optimal hyperparameters\n",
    "rf_smote_model = grid_search.best_estimator_\n",
    "\n",
    "rf_smote_model.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d96e_cGYntdC"
   },
   "source": [
    "#### Evaluating the model on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UOtnfwoNntdC"
   },
   "outputs": [],
   "source": [
    "# Predictions on the train set\n",
    "y_train_pred_smote = rf_smote_model.predict(X_train_smote)\n",
    "display_scores(y_train_smote, y_train_pred_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bu9k7WP_ntdC"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_train_pred_proba = rf_smote_model.predict_proba(X_train_smote)[:,1]\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_train_smote, y_train_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kho52QD8ntdC"
   },
   "source": [
    "#### Evaluating the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GQUNXs3JntdC"
   },
   "outputs": [],
   "source": [
    "# Evaluating model on the test data\n",
    "y_pred = rf_smote_model.predict(X_test)\n",
    "display_scores(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IaAbIWACntdC"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_test_pred_smote = rf_smote_model.predict_proba(X_test)[:,1]\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_test, y_test_pred_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-NmvFA1ntdC"
   },
   "source": [
    "#### Model Summary\n",
    "- Train set\n",
    "    - ROC score : 100%\n",
    "    - F1 score: 98.92%\n",
    "- Test set\n",
    "    - ROC score : 98%\n",
    "    - F1 score: 52.89%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owscWC1xntdC"
   },
   "source": [
    "# XGBoost on balanced data with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hKHIoTUnntdC"
   },
   "outputs": [],
   "source": [
    "# creating a KFold object \n",
    "folds = 5\n",
    "\n",
    "# specify range of hyperparameters\n",
    "param_grid = {'learning_rate': [0.2, 0.6], \n",
    "             'subsample': [0.3, 0.6, 0.9]}          \n",
    "\n",
    "\n",
    "# specify model\n",
    "xgb_model = XGBClassifier(max_depth=2, n_estimators=200)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = xgb_model, \n",
    "                        param_grid = param_grid, \n",
    "                        scoring= 'roc_auc', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        n_jobs=-1,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eqqohgGBntdC"
   },
   "outputs": [],
   "source": [
    "# cv results\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PJMfnmkOntdD"
   },
   "outputs": [],
   "source": [
    "# Printing the optimal score and hyperparameters\n",
    "print(\"Best roc auc score : \", model_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4MDJYOdSntdD"
   },
   "outputs": [],
   "source": [
    "print(model_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMGW9_PRntdD"
   },
   "source": [
    "#### Model with optimal hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iJP1HGKDntdD"
   },
   "outputs": [],
   "source": [
    "model_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P1CCIuGGntdD"
   },
   "outputs": [],
   "source": [
    "# fit model on training data\n",
    "xgb_smote_model = model_cv.best_estimator_\n",
    "xgb_smote_model.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXkliNS6ntdD"
   },
   "source": [
    "#### Evaluating the model on the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78vQ2O7yntdD"
   },
   "outputs": [],
   "source": [
    "y_train_pred = xgb_smote_model.predict(X_train_smote)\n",
    "display_scores(y_train_smote, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_gKTjbzntdD"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_train_pred_proba = xgb_smote_model.predict_proba(X_train_smote)[:,1]\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_train_smote, y_train_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-k1A2rlCntdD"
   },
   "source": [
    "#### Evaluating the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZeEQvRrZntdD"
   },
   "outputs": [],
   "source": [
    "y_pred = xgb_smote_model.predict(X_test)\n",
    "display_scores(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0vxgGa7untdD"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_test_pred_proba = xgb_smote_model.predict_proba(X_test)[:,1]\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_test, y_test_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6NFqLOXntdD"
   },
   "source": [
    "#### Model Summary\n",
    "- Train set\n",
    "    - ROC score : 100.0%\n",
    "    - F1 score: 99.89%\n",
    "    \n",
    "- Test set\n",
    "    - ROC score : 97%\n",
    "    - F1 score: 52.44%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjWuG3BintdD"
   },
   "source": [
    "## ADASYN (Adaptive Synthetic Sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3z85jJlntdD"
   },
   "source": [
    "### Print the class distribution after applying ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J3d-i70XntdD"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from imblearn import over_sampling\n",
    "\n",
    "ada = over_sampling.ADASYN(random_state=42)\n",
    "X_train_adasyn, y_train_adasyn = ada.fit_resample(X_train, y_train)\n",
    "# Artificial minority samples and corresponding minority labels from ADASYN are appended\n",
    "# below X_train and y_train respectively\n",
    "# So to exclusively get the artificial minority samples from ADASYN, we do\n",
    "X_train_adasyn_1 = X_train_adasyn[X_train.shape[0]:]\n",
    "\n",
    "X_train_1 = X_train.to_numpy()[np.where(y_train==1.0)]\n",
    "X_train_0 = X_train.to_numpy()[np.where(y_train==0.0)]\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [20, 20]\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
    "plt.scatter(X_train_adasyn_1.iloc[:X_train_1.shape[0], 0], X_train_adasyn_1.iloc[:X_train_1.shape[0], 1],\n",
    "            label='Artificial ADASYN Class-1 Examples')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
    "plt.scatter(X_train_0[:X_train_1.shape[0], 0], X_train_0[:X_train_1.shape[0], 1], label='Actual Class-0 Examples')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebpKoArantdD"
   },
   "source": [
    "# Logistic Regression on balanced data with ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_7WMmH7ntdD"
   },
   "outputs": [],
   "source": [
    "# Creating KFold object with 5 splits\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Specify params\n",
    "params = {\"C\": [0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "# Specifing score as roc-auc\n",
    "model_cv = GridSearchCV(estimator = LogisticRegression(),\n",
    "                        param_grid = params, \n",
    "                        scoring= 'roc_auc', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True) \n",
    "\n",
    "# Fit the model\n",
    "model_cv.fit(X_train_adasyn, y_train_adasyn)\n",
    "#print the evaluation result by choosing a evaluation metric\n",
    "print('Best ROC AUC score: ', model_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gaMLufY5ntdD"
   },
   "outputs": [],
   "source": [
    "#print the optimum value of hyperparameters\n",
    "print('Best hyperparameters: ', model_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hR5QyD2fntdE"
   },
   "outputs": [],
   "source": [
    "# cross validation results\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3BGqriKSntdE"
   },
   "outputs": [],
   "source": [
    "# plot of C versus train and validation scores\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(cv_results['param_C'], cv_results['mean_test_score'])\n",
    "plt.plot(cv_results['param_C'], cv_results['mean_train_score'])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('ROC AUC')\n",
    "plt.legend(['test result', 'train result'], loc='upper left')\n",
    "plt.xscale('log')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJnnXzA0ntdE"
   },
   "source": [
    "#### Logistic Regression with optimal C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bagg75CQntdE"
   },
   "outputs": [],
   "source": [
    "model_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZ6FA8lnntdE"
   },
   "outputs": [],
   "source": [
    "# Instantiating the model\n",
    "logreg_adasyn_model = model_cv.best_estimator_\n",
    "\n",
    "# Fitting the model \n",
    "logreg_adasyn_model.fit(X_train_adasyn, y_train_adasyn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNdyicQhntdE"
   },
   "source": [
    "#### Evaluating the model with train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7jWHvbgantdE"
   },
   "outputs": [],
   "source": [
    "# Evaluating on test data\n",
    "y_train_pred = logreg_adasyn_model.predict(X_train_adasyn)\n",
    "display_scores(y_train_adasyn, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MyJNlviEntdE"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_train_pred_proba = logreg_adasyn_model.predict_proba(X_train_adasyn)[:,1]\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_train_adasyn, y_train_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bONUv04pntdE"
   },
   "source": [
    "#### Evaluating on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qA0xHdubntdE"
   },
   "outputs": [],
   "source": [
    "# Evaluating on test data\n",
    "y_pred = logreg_adasyn_model.predict(X_test)\n",
    "display_scores(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lo4WlB_RntdE"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_test_pred_proba = logreg_adasyn_model.predict_proba(X_test)[:,1]\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_test, y_test_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gch5w1uSntdE"
   },
   "source": [
    "#### Model Summary\n",
    "- Train set\n",
    "    - ROC score : 97%\n",
    "    - F1 score: 90.49%\n",
    "- Test set\n",
    "    - ROC score : 97%\n",
    "    - F1 score: 3.39%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vxk5weO_ntdE"
   },
   "source": [
    "# Decision Tree on balanced data with ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OAbzUc48ntdE"
   },
   "outputs": [],
   "source": [
    "# Create the parameter grid \n",
    "param_grid = {\n",
    "    'max_depth': range(5, 15, 5),\n",
    "    'min_samples_leaf': range(50, 150, 50),\n",
    "    'min_samples_split': range(50, 150, 50),\n",
    "}\n",
    "\n",
    "\n",
    "# Instantiate the grid search model\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator = dtree, \n",
    "                           param_grid = param_grid, \n",
    "                           scoring= 'roc_auc',\n",
    "                           cv = 5, \n",
    "                           n_jobs=-1,\n",
    "                           verbose = 1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_adasyn,y_train_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ojb8YxulntdE"
   },
   "outputs": [],
   "source": [
    "# Printing the optimal roc score and hyperparameters\n",
    "print(\"Best roc auc score : \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H9ayByB9ntdE"
   },
   "outputs": [],
   "source": [
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYQ6Q55YntdE"
   },
   "source": [
    "#### Model with optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DPXcU5ANntdE"
   },
   "outputs": [],
   "source": [
    "# Model with optimal hyperparameters\n",
    "dt_adasyn_model =grid_search.best_estimator_\n",
    "dt_adasyn_model.fit(X_train_adasyn, y_train_adasyn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AcjLaMcintdF"
   },
   "source": [
    "#### Evaluating the model on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NmrSNQU2ntdF"
   },
   "outputs": [],
   "source": [
    "# Evaluating model on the test data\n",
    "y_train_pred = dt_adasyn_model.predict(X_train_adasyn)\n",
    "display_scores(y_train_adasyn, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A7CeQCOCntdF"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_train_pred_proba = dt_adasyn_model.predict_proba(X_train_adasyn)[:,1]\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_train_adasyn, y_train_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7iFLt3AkntdF"
   },
   "source": [
    "#### Evaluating the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zTvGRihEntdF"
   },
   "outputs": [],
   "source": [
    "# Evaluating model on the test data\n",
    "y_pred = dt_adasyn_model.predict(X_test)\n",
    "display_scores(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YCMbtigQntdF"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_test_pred_proba = dt_adasyn_model.predict_proba(X_test)[:,1]\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_test, y_test_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dEjtdY4zntdF"
   },
   "source": [
    "#### Model Summary\n",
    "- Train set\n",
    "    - ROC score : 99%\n",
    "    - F1 score: 98%\n",
    "    \n",
    "- Test set\n",
    "    - ROC score : 95%\n",
    "    - F1 score: 7.6%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4QpIeYmNntdF"
   },
   "source": [
    "# RandomForest on balanced data with ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jX64DKorntdF"
   },
   "outputs": [],
   "source": [
    "# Create the parameter grid \n",
    "param_grid = {\n",
    "    'max_depth': range(5, 15, 5),\n",
    "    'min_samples_leaf': range(50, 150, 50),\n",
    "    'min_samples_split': range(50, 150, 50),\n",
    "}\n",
    "\n",
    "\n",
    "# Instantiate the grid search model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = param_grid, \n",
    "                           scoring= 'roc_auc',\n",
    "                           cv = 5, \n",
    "                           n_jobs=-1,\n",
    "                           verbose = 1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_adasyn,y_train_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EqdUJFWlntdF"
   },
   "outputs": [],
   "source": [
    "# Printing the optimal roc score and hyperparameters\n",
    "print(\"Best roc auc score : \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xnhUWvfPntdF"
   },
   "outputs": [],
   "source": [
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64iPQTBMntdF"
   },
   "source": [
    "#### Model with optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W8e70XOcntdF"
   },
   "outputs": [],
   "source": [
    "# Model with optimal hyperparameters\n",
    "rf_adasyn_model =grid_search.best_estimator_\n",
    "rf_adasyn_model.fit(X_train_adasyn, y_train_adasyn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7K5a0HqntdF"
   },
   "source": [
    "#### Evaluating the model on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zuFWqghNntdF"
   },
   "outputs": [],
   "source": [
    "# Evaluating model on the test data\n",
    "y_train_pred = rf_adasyn_model.predict(X_train_adasyn)\n",
    "display_scores(y_train_adasyn, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NfEmYuITntdF"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_train_pred_proba = rf_adasyn_model.predict_proba(X_train_adasyn)[:,1]\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_train_adasyn, y_train_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pU8ORYBWntdF"
   },
   "source": [
    "#### Evaluating the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FdpJ6k9tntdG"
   },
   "outputs": [],
   "source": [
    "# Evaluating model on the test data\n",
    "y_pred = rf_adasyn_model.predict(X_test)\n",
    "display_scores(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8K0iB7R1ntdG"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_test_pred_proba = rf_adasyn_model.predict_proba(X_test)[:,1]\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_test, y_test_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8bO46y4ntdG"
   },
   "source": [
    "#### Model Summary\n",
    "- Train set\n",
    "    - ROC score : 100%\n",
    "    - F1 score: 99.16%\n",
    "    \n",
    "- Test set\n",
    "    - ROC score : 98%\n",
    "    - F1 score: 20.6%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIHN7KtDntdG"
   },
   "source": [
    "# XGBoost on balanced data with ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oq5kKkHGntdG"
   },
   "outputs": [],
   "source": [
    "# creating a KFold object \n",
    "folds = 5\n",
    "\n",
    "# specify range of hyperparameters\n",
    "param_grid = {'learning_rate': [0.2, 0.6], \n",
    "             'subsample': [0.3, 0.6, 0.9]}          \n",
    "\n",
    "\n",
    "# specify model\n",
    "xgb_model = XGBClassifier(max_depth=2, n_estimators=200)\n",
    "\n",
    "# set up GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = xgb_model, \n",
    "                        param_grid = param_grid, \n",
    "                        scoring= 'roc_auc', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        n_jobs=-1,\n",
    "                        return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv.fit(X_train_adasyn, y_train_adasyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e41q2INUntdG"
   },
   "outputs": [],
   "source": [
    "# cv results\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2LLLM5EntdG"
   },
   "outputs": [],
   "source": [
    "# Printing the optimal score and hyperparameters\n",
    "print(\"Best roc auc score : \", model_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_xn90JBqntdG"
   },
   "outputs": [],
   "source": [
    "print(model_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ic0deNNentdG"
   },
   "source": [
    "#### Model with optimal hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q2ggBx5ZntdG"
   },
   "outputs": [],
   "source": [
    "model_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KlWlfDu4ntdG"
   },
   "outputs": [],
   "source": [
    "# Model with optimal hyperparameter\n",
    "xgb_adasyn_model = model_cv.best_estimator_\n",
    "xgb_adasyn_model.fit(X_train_adasyn,y_train_adasyn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DGa9wuIntdG"
   },
   "source": [
    "#### Evaluating the model on the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QQpRAjOsntdG"
   },
   "outputs": [],
   "source": [
    "# Predicting on the train set\n",
    "y_train_pred = xgb_adasyn_model.predict(X_train_adasyn)\n",
    "# Printing the scores\n",
    "display_scores(y_train_adasyn, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8UXOChh_ntdG"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_train_pred_proba = xgb_adasyn_model.predict_proba(X_train_adasyn)[:,1]\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_train_adasyn, y_train_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8k6Hy9I0ntdG"
   },
   "source": [
    "#### Evaluating the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zRuAK96nntdG"
   },
   "outputs": [],
   "source": [
    "y_pred = xgb_adasyn_model.predict(X_test)\n",
    "display_scores(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U6n2eEU-ntdG"
   },
   "outputs": [],
   "source": [
    "# Predicted probability\n",
    "y_test_pred_proba = xgb_adasyn_model.predict_proba(X_test)[:,1]\n",
    "# Plot the ROC curve\n",
    "draw_roc(y_test, y_test_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMWOpIdZntdH"
   },
   "source": [
    "#### Model Summary\n",
    "- Train set\n",
    "    - ROC score : 100.0%\n",
    "    - F1 score: 99.79%\n",
    "- Test set\n",
    "    - ROC score : 98%\n",
    "    - F1 score: 35.22%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31fF-q52ntdH"
   },
   "source": [
    "### Select the oversampling method which shows the best result on a model\n",
    "We have used several balancing technique to solve the minority class imbalance. We have used Random Oversampling, SMOTE, and Adasyn technique to balance the dataset and then we performed logistic regression, random forest and XGBoost algorithms to build models on each sampling method.\n",
    "\n",
    "After conducting the experiment on each oversampling method, we have found that XGBoost model is performing well on the  dataset which is balanced with AdaSyn technique. We got ROC score 100% on train data and 98% on the test data and F1 score 100% on train data and 78% in the test data. \n",
    "\n",
    "Hence, we conclude that the `XGBoost model with Adasyn` is the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5MYM43mrntdH"
   },
   "source": [
    "### Print the important features of the best model to understand the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vxK_qZhontdI"
   },
   "outputs": [],
   "source": [
    "var_imp = []\n",
    "for i in xgb_adasyn_model.feature_importances_:\n",
    "    var_imp.append(i)\n",
    "print('Top var =', var_imp.index(np.sort(xgb_adasyn_model.feature_importances_)[-1])+1)\n",
    "print('2nd Top var =', var_imp.index(np.sort(xgb_adasyn_model.feature_importances_)[-2])+1)\n",
    "print('3rd Top var =', var_imp.index(np.sort(xgb_adasyn_model.feature_importances_)[-3])+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b49wwzYantdI"
   },
   "outputs": [],
   "source": [
    "# Variable on Index-14 and Index-4 seems to be the top 2 variables\n",
    "top_var_index = var_imp.index(np.sort(xgb_adasyn_model.feature_importances_)[-1])\n",
    "second_top_var_index = var_imp.index(np.sort(xgb_adasyn_model.feature_importances_)[-2])\n",
    "\n",
    "X_train_1 = X_train.to_numpy()[np.where(y_train==1.0)]\n",
    "X_train_0 = X_train.to_numpy()[np.where(y_train==0.0)]\n",
    "\n",
    "np.random.shuffle(X_train_0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "plt.scatter(X_train_1[:, top_var_index], X_train_1[:, second_top_var_index], label='Actual Class-1 Examples')\n",
    "plt.scatter(X_train_0[:X_train_1.shape[0], top_var_index], X_train_0[:X_train_1.shape[0], second_top_var_index],\n",
    "            label='Actual Class-0 Examples')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7mOaiGantdJ"
   },
   "source": [
    "#### Print the FPR,TPR & select the best threshold from the roc curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cdg4RAqyntdJ"
   },
   "outputs": [],
   "source": [
    "print('Train auc =', metrics.roc_auc_score(y_train_adasyn, y_train_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01y6PqKlntdJ"
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_train_adasyn, y_train_pred_proba )\n",
    "threshold = thresholds[np.argmax(tpr-fpr)]\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTEi3Q90ntdJ"
   },
   "source": [
    "We have found that 77.97% is the threshold for which TPR is the highest and FPR is the lowest and we get 99.99% ROC score on the train data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prOolKDentdJ"
   },
   "source": [
    "### Summary to the business\n",
    "Here, we have to focus on a high recall in order to detect actual fraudulent transactions in order to save the banks from high-value fraudulent transactions,\n",
    "\n",
    "After performing several models, we have seen that in the balanced dataset with ADASYN technique the XGBoost model has good ROC score(98%) and also high Recall(86%). Hence, we can go with the XGBoost model here."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "-60v9ta7ntc3",
    "JTVBYXXlntc4",
    "-xaVxTzEntc5",
    "q9U_HgMentc8",
    "_iOwYgdHntc9",
    "L0mkphzentc-",
    "ZoAP8nzqntc_",
    "1qSeNWb1ntdA",
    "Alu0KXhLntdA",
    "X9Tw9hOBntdA",
    "boZwQObRntdA",
    "2tyNE13pntdB",
    "gXgPNJ1KntdB",
    "WCR8rPBpntdB",
    "76kF7RfLntdB",
    "gyXjTAnVntdB",
    "XOPGZ4huntdB",
    "VVRoW0edntdC",
    "d96e_cGYntdC",
    "Kho52QD8ntdC",
    "N-NmvFA1ntdC",
    "owscWC1xntdC",
    "CMGW9_PRntdD",
    "AXkliNS6ntdD",
    "-k1A2rlCntdD",
    "f6NFqLOXntdD",
    "xjWuG3BintdD",
    "y3z85jJlntdD",
    "ebpKoArantdD",
    "lJnnXzA0ntdE",
    "BNdyicQhntdE",
    "bONUv04pntdE",
    "gch5w1uSntdE",
    "Vxk5weO_ntdE",
    "LYQ6Q55YntdE",
    "AcjLaMcintdF",
    "7iFLt3AkntdF",
    "dEjtdY4zntdF",
    "4QpIeYmNntdF",
    "64iPQTBMntdF",
    "a7K5a0HqntdF",
    "pU8ORYBWntdF",
    "O8bO46y4ntdG",
    "ic0deNNentdG",
    "7DGa9wuIntdG",
    "8k6Hy9I0ntdG",
    "WMWOpIdZntdH",
    "31fF-q52ntdH",
    "5MYM43mrntdH",
    "a7mOaiGantdJ",
    "prOolKDentdJ"
   ],
   "name": "credit-card-fraud-detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
